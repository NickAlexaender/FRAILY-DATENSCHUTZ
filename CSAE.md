Externally Published Standards Against Child Sexual Abuse & Exploitation (CSAE)

Effective date: 2026.01.01
Applies to: FRAILY, including all users, content, messages, profiles, media uploads, and any community features.

1) Zero-tolerance policy

FRAILY has zero tolerance for child sexual abuse and exploitation (CSAE). We prohibit any content, behavior, or activity that sexualizes, exploits, endangers, or targets minors.

2) What we prohibit (CSAE)

We prohibit, and will remove and act on, including but not limited to:

Child sexual abuse material (CSAM) in any form (images, videos, audio, animations, illustrations, AI-generated or manipulated media, links, hashes, or instructions to access CSAM).

Sexual content involving minors, including depictions of minors in sexual situations, nudity that is sexualized, or “age-play” content involving minors.

Grooming and predatory behavior, including attempts to befriend or manipulate a minor for sexual purposes, requesting sexual content, or moving conversations off-platform to avoid safety controls.

Sexual solicitation of minors, including requesting or offering sexual acts, explicit photos, or “sexting.”

Trafficking, coercion, extortion, or “sextortion” involving minors, including threats to share images or demands for more explicit material.

Sharing personal information to facilitate exploitation, including arranging in-person meetings with minors for sexual purposes.

Content that promotes, normalizes, or instructs CSAE, including “how-to” guidance, communities, or advocacy for sexual activity with minors.

3) Age requirements and minor safety

Users must be at least 13 to use FRAILY.

We do not allow adults to use FRAILY to contact minors for romantic or sexual purposes.

Where relevant, we apply safeguards such as age-gating, limited discoverability, and additional protections for younger users.

4) Detection and prevention

We use a combination of safety measures to prevent and address CSAE, which may include:

User reports and human review

Proactive detection (automated signals to identify known or suspected CSAE patterns)

Link and media risk controls (where applicable)

Repeat-offender prevention (device/account-level signals, where legally permitted)

We design these measures to prioritize child safety while respecting user privacy and applicable laws.

5) Reporting CSAE in the app

If you see content or behavior that may involve CSAE:

Use the in-app Report function (available on profiles, messages, and content).

Or contact us at: NICK.LEHMACHER@GMX.DE with relevant details (usernames, message timestamps, links, screenshots if safe/legal to provide).

Do not share or forward suspected CSAM. Report it—sharing can further harm victims and may be illegal.

6) Enforcement actions

If we detect or receive a report of CSAE, we may take one or more actions immediately:

Remove content

Restrict features (e.g., messaging, uploading)

Suspend or permanently ban accounts

Preserve relevant information as required or permitted by law

Report to appropriate authorities and/or relevant hotlines when legally required or appropriate

7) Cooperation with authorities and legal compliance

We comply with applicable laws regarding CSAE/CSAM and cooperate with lawful requests from competent authorities. Where required, we may file reports with designated organizations or agencies and preserve information consistent with legal obligations.

8) Appeals

If your account is actioned and you believe it was a mistake, you can appeal by contacting NICK.LEHMACHER@GMX.DE.
Note: For CSAE-related enforcement, we may limit the details we can share to protect investigations and safety.

9) Transparency and updates

We may update these standards to reflect evolving safety risks and legal requirements. Updates will be posted publicly with a revised effective date.

10) Contact

Safety contact: NICK.LEHMACHER@GMX.DE
